{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Optimisation II:  A simple neural network \n",
    "\n",
    "### Nom(s): \n",
    "### Pr√©nom(s): \n",
    "### Groupe:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are  60000 images in the train set\n",
      "there are  10000 images in the test set\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Load train data\n",
    "#\n",
    "Xtrain = np.load('train-images.npy')\n",
    "Xtrain = np.array([x.ravel()/255 for x in Xtrain])\n",
    "Xtrain = Xtrain.reshape(Xtrain.shape[0],Xtrain.shape[1],1)\n",
    "Ytrain = np.load('train-labels.npy')\n",
    "targets_train = []\n",
    "\n",
    "#\n",
    "# Convert digits to 10x1 vectors\n",
    "#\n",
    "for lab in Ytrain:\n",
    "    v      = np.zeros((10,1))\n",
    "    v[lab] = 1\n",
    "    targets_train+=[np.array(v)]\n",
    "\n",
    "#\n",
    "# Load test data\n",
    "#\n",
    "Xtest        = np.load('t10k-images.npy')\n",
    "Xtest        = np.array([x.ravel()/255 for x in Xtest])\n",
    "Xtest        = Xtest.reshape(Xtest.shape[0],Xtest.shape[1],1)\n",
    "Ytest        = np.load('t10k-labels.npy')\n",
    "targets_test = []\n",
    "\n",
    "#\n",
    "# Convert digits to 10x1 vectors\n",
    "#\n",
    "for lab in Ytest:\n",
    "    v = np.zeros((10,1))\n",
    "    v[lab]=1\n",
    "    targets_test+=[np.array(v)]\n",
    "#\n",
    "# Outputs\n",
    "#\n",
    "print('there are ',Xtrain.shape[0],'images in the train set')\n",
    "print('there are ',Xtest.shape[0],'images in the test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the activation function\n",
    "\n",
    " The activation function defines the output of a node given a set of inputs. We use the <a href=\"https://en.wikipedia.org/wiki/Softmax_function\">softmax</a> function defined by\n",
    " \n",
    " $$\\sigma_{\\alpha} : \\mathbb{R}^p\\rightarrow [0,1]^p, \\quad \\mbox{ s.t.} \\quad[\\sigma_{\\alpha}(x)]_i=\\frac{e^{x_i+\\alpha_i}}{\\displaystyle{\\sum_{j=1}^{p}e^{x_j+\\alpha_j}}}\\quad \\forall i=1:p. $$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Nonlinear activation function\n",
    "#\n",
    "def softmax(x,alpha):\n",
    "    \"\"\"\n",
    "    Softmax unit activation function \n",
    "    x    : Numpy array\n",
    "    alpha: scalar\n",
    "    \"\"\" \n",
    "    temp = np.exp(x + alpha)\n",
    "    value = temp / np.sum(temp)\n",
    "    \n",
    "    \n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# Example of a plot of the activation function\n",
    "#\n",
    "t     = np.arange(-5,5,0.1)\n",
    "alpha = np.arange(-50,50,1)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(t,softmax(t,alpha))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of a simple neural network\n",
    "\n",
    "We use a one-layer fully-connected neural network with the <a href=\"https://en.wikipedia.org/wiki/Softmax_function\">softmax</a> activation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(x,W):\n",
    "    \"\"\"\n",
    "    # One-layer fully connected neural network\n",
    "    # x: image, i.e. 784x1 vector (28x28)\n",
    "    # W: weight matrices of shape 10x784   \n",
    "    \"\"\"\n",
    "    temp = W @ x\n",
    "    pred = softmax(temp, -np.max(temp))\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the loss function\n",
    "\n",
    "The loss function is the <a href=\"https://en.wikipedia.org/wiki/Cross_entropy\">cross-entropy</a> defined by \n",
    "\n",
    "$$J(W)=-\\sum_{i=1}^N p_i \\log(q_i(W)),$$ where $N$ is the number of classes, $(p_i)_{i=1:N}$ are the probabilities of  a data from the training set to belong to a class (0 or 1 because the labels are known), and $(q_i(W))_{i=1:N}$ are the predicted probabilities from the model\n",
    "\n",
    "$$\\forall i=1:N, \\quad q_i(W)=[\\sigma_{\\alpha}(Wx)]_i.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Loss function = Cross-entropy\n",
    "#\n",
    "def cross_entropy(pred,target,x):\n",
    "    \"\"\"\n",
    "    pred:   predicted probabilities (q(W))\n",
    "    target: probabilities (p)\n",
    "    x:      image \n",
    "    \"\"\" \n",
    "    ce   = -target.T @ np.log(pred)\n",
    "    u    = np.ones((np.shape(pred)[0], 1))\n",
    "    grad = -(- (u.T @ target) * pred @ x.T + target @ x.T).flatten() \n",
    "    return ce,grad\n",
    "#\n",
    "# Main function \n",
    "#\n",
    "def f(W,x,target):\n",
    "    \"\"\"\n",
    "    W:      weights\n",
    "    target: probabilities (p)\n",
    "    x:      image\n",
    "    \"\"\"\n",
    "    pred    = NN(x,W)\n",
    "    ce,grad = cross_entropy(pred,target,x)\n",
    "    \n",
    "    return ce,grad,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.03989252]]\n",
      "[-2.03989234]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Test information on the gradient with calls of f\n",
    "#\n",
    "\n",
    "# Define weight matrices\n",
    "W      = np.random.rand(10,Xtrain.shape[1])\n",
    "eps    = 1e-8\n",
    "d      = np.random.rand(10,Xtrain.shape[1])\n",
    "Wtilde = W+eps*d\n",
    "\n",
    "# Retrieve the information on the gradients\n",
    "res    = (f(Wtilde,Xtrain[0],targets_train[0])[0]-f(W,Xtrain[0],targets_train[0])[0])/eps\n",
    "print(res)\n",
    "\n",
    "g      = f(W,Xtrain[0],targets_train[0])[1]\n",
    "print(g.T.dot(d.reshape(7840,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Function to create batches of samples to be used later in the training phase\n",
    "#\n",
    "def create_batches(x,bs):\n",
    "    \"\"\"\n",
    "    x : set to be considered (array)\n",
    "    bs: batch size (scalar)\n",
    "    \"\"\"\n",
    "    batches = []\n",
    "    ind     = np.arange(x.shape[0])\n",
    "    random.shuffle(ind)\n",
    "    nbatch  = ind.shape[0]//bs\n",
    "    rest    = ind.shape[0]%bs\n",
    "    \n",
    "    for n in range(nbatch):\n",
    "        batches +=[ind[bs*n:bs*(n+1)]]\n",
    "    \n",
    "    # Put the remaining elements in a last batch\n",
    "    if rest !=0:        \n",
    "        batches += [ind[-rest:]]\n",
    "        \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history    = {}\n",
    "eta        = 1e-5 # learning rate\n",
    "momentum   = 0.   # momemtum factor\n",
    "N_EPOCHS   = 10  \n",
    "BatchSizes = [10000,1024,256] # try different batch sizes for the analysis\n",
    "\n",
    "for bs in BatchSizes:\n",
    "    #\n",
    "    # Sensitivity to the batch size to be investigated in the analysis\n",
    "    #\n",
    "    print('batch size=',bs)\n",
    "    \n",
    "    history[bs]={'train loss':[],'train acc':[],'test loss':[0], 'test acc':[0]}\n",
    "    \n",
    "    # Initialization of the weights\n",
    "    w = np.random.rand(10,Xtrain.shape[1])\n",
    "    \n",
    "    for n in range(N_EPOCHS):\n",
    "        # Minimization of the loss function\n",
    "        \n",
    "        Batches=create_batches(Xtrain,bs)\n",
    "        \n",
    "        for batch in Batches:\n",
    "            # Loop on the batches\n",
    "            #\n",
    "            # TO DO\n",
    "            #\n",
    "            for ind in batch:\n",
    "                x = train[ind]\n",
    "                   \n",
    "        # Test accuracy at the end of each epoch  \n",
    "        #\n",
    "        # TO DO\n",
    "        #\n",
    "        \n",
    "        print('Epoch number :', n+1,'test accuracy:',history[bs]['test acc'][n+1],'test loss',history[bs]['test loss'][n+1])\n",
    "        \n",
    "\n",
    "    print('\\n')            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots of the evolution of the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bs in BatchSizes:\n",
    "       \n",
    "    n_batch = Xtrain.shape[0]//bs     \n",
    "    if Xtrain.shape[0]%bs!=0:\n",
    "        n_batch+=1\n",
    "        \n",
    "    E  = [n_batch*n for n in np.arange(N_EPOCHS+1)]\n",
    "    Ep = [str(n) for n in np.arange(N_EPOCHS+1)]\n",
    "    \n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.plot(history[bs]['train loss'],label = 'training loss')\n",
    "    plt.plot(E[1:],history[bs]['test loss'][1:],linewidth=2.5,label = 'test loss')\n",
    "    plt.xticks(E,Ep)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss Value')\n",
    "    #plt.ylim([0,np.max(history[bs]['test loss'])+2])\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.title(f'model trained with a Batch size of {bs} samples and learning rate of {eta}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots of the evolution of the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bs in BatchSizes:\n",
    "    print(bs)   \n",
    "    n_batch = Xtrain.shape[0]//bs     \n",
    "    if Xtrain.shape[0]%bs!=0:\n",
    "        n_batch+=1\n",
    "        \n",
    "    print(n_batch)\n",
    "    E=[n_batch*n for n in np.arange(N_EPOCHS+1)]\n",
    "    Ep = [str(n) for n in np.arange(N_EPOCHS+1)]\n",
    "    \n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.plot(history[bs]['train acc'] ,label  = 'training acuracy')\n",
    "    plt.plot(E[1:],history[bs]['test acc'][1:],linewidth=2.5,label = 'test acuracy')\n",
    "    plt.xticks(E,Ep)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(True)\n",
    "    plt.title(f'model trained with a Batch size of {bs} samples and learning rate of {eta}')\n",
    "    plt.ylim([0,1])\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the results\n",
    "\n",
    "Please provide your comments on the sensitivity of the results to the parameters involved in the learning process (batch size, learning rate, momentum)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
